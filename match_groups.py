import json
import math
from typing import Dict, List, Any, Optional

# --- æª”æ¡ˆè·¯å¾‘è¨­å®š ---
DIVISION_EXAM_FILE = 'division_exam_data.json'
SCORE_DISTRIBUTION_FILE = 'score_distribution.json'
OUTPUT_FILE = 'very_result_112.json'

# --- å‡½æ•¸å®šç¾©ï¼šå‰µå»ºç§‘ç›®çµ„åˆåˆ°çµ„åˆ¥ä»£è™Ÿçš„æ˜ å°„è¡¨ ---

def create_subject_group_map(score_data: Dict[str, Any]) -> Dict[frozenset, str]:
    """
    å¾åˆ†æ•¸åˆ†ä½ˆæ•¸æ“šä¸­å‰µå»ºç§‘ç›®çµ„åˆåˆ°çµ„åˆ¥ä»£è™Ÿçš„æ˜ å°„è¡¨ã€‚
    ä½¿ç”¨ frozenset (ä¸å¯è®Šé›†åˆ) ä½œç‚ºéµï¼Œç¢ºä¿åŒ¹é…ä¸ä¾è³´é †åºã€‚
    """
    subject_map = {}
    for group_id, data in score_data.items():
        subjects: List[str] = data.get("ç§‘ç›®çµ„åˆ", [])
        subject_set = frozenset(subjects)
        if subject_set in subject_map:
            # å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œæ‡‰ç¢ºèªæ˜¯å¦çœŸçš„æœ‰å¤šå€‹çµ„åˆ¥ä½¿ç”¨å®Œå…¨ç›¸åŒçš„ç§‘ç›®çµ„åˆ
            pass 
        subject_map[subject_set] = group_id
    return subject_map

# --- å‡½æ•¸å®šç¾©ï¼šè¨ˆç®—é”æ¨™æ¯”ä¾‹ ---

def get_percentile_from_score(
    dept_data: Dict[str, Any], 
    group_id: str, 
    score_data: Dict[str, Any]
) -> Optional[float]:
    """
    æ ¹æ“šç§‘ç³»çš„åŠ æ¬Šå¹³å‡åˆ†æ•¸ã€ç§‘ç›®æ•¸é‡å’Œçµ„åˆ¥ä»£è™Ÿï¼Œå¾åˆ†æ•¸åˆ†ä½ˆæ•¸æ“šä¸­æŸ¥æ‰¾ç´¯ç©ç™¾åˆ†æ¯”ã€‚
    
    é‚è¼¯ï¼š (åŠ æ¬Šå¹³å‡åˆ†æ•¸ * ç§‘ç›®æ•¸é‡) -> å‘ä¸Šå–æ•´ -> æŸ¥æ‰¾ç™¾åˆ†æ¯”ã€‚
    
    Args:
        dept_data (Dict): å–®ä¸€ç§‘ç³»çš„æ•¸æ“šï¼ŒåŒ…å« "ç§‘ç›®å€æ•¸" å’Œ "ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–"ã€‚
        group_id (str): åŒ¹é…åˆ°çš„çµ„åˆ¥ä»£è™Ÿ (e.g., "013")ã€‚
        score_data (Dict): score_distribution.json çš„å®Œæ•´å…§å®¹ã€‚
        
    Returns:
        Optional[float]: æ‰¾åˆ°çš„ç´¯ç©ç™¾åˆ†æ¯”ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› Noneã€‚
    """
    
    score_average = dept_data.get("ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–") # é€™æ˜¯åŠ æ¬Šå¹³å‡åˆ†æ•¸
    multipliers = dept_data.get("ç§‘ç›®å€æ•¸", {})
    
    if not isinstance(score_average, (int, float)):
        return None # å¦‚æœåˆ†æ•¸ç„¡æ•ˆï¼Œå‰‡ä¸è™•ç†

    # 1. ç²å–ç§‘ç›®æ•¸é‡ (N_subjects)
    # ç§‘ç›®æ•¸é‡æ˜¯ç§‘ç›®å€æ•¸å­—å…¸ä¸­çš„éµçš„æ•¸é‡
    num_subjects = len(multipliers) 
    
    if num_subjects == 0:
        return None

    # 2. è¨ˆç®—é‚„åŸå¾Œçš„åŸå§‹ç¸½åˆ† (S_total)
    # åŸå§‹ç¸½åˆ† = åŠ æ¬Šå¹³å‡åˆ†æ•¸ * ç§‘ç›®æ•¸é‡
    raw_total_score = score_average * num_subjects
    
    # 3. å‘ä¸Šå–æ•´
    # ä½¿ç”¨ math.ceil() å‡½æ•¸
    ceil_score = math.ceil(raw_total_score)
    
    # å°‡åˆ†æ•¸è½‰æ›ç‚ºå­—ä¸²éµ (e.g., 258.0 -> "258")
    score_key = str(int(ceil_score))
    
    # 4. æŸ¥æ‰¾æ•¸æ“š
    group_data = score_data.get(group_id)
    if not group_data:
        return None
        
    percentiles: Dict[str, float] = group_data.get("ç´¯ç©ç™¾åˆ†æ¯”", {})
    
    # 5. è¿”å›ç™¾åˆ†æ¯”
    # é€™è£¡çš„ç™¾åˆ†æ¯” p è¡¨ç¤º >= score_key çš„è€ƒç”Ÿæ‰€ä½”çš„æ¯”ä¾‹
    return percentiles.get(score_key)


# --- å‡½æ•¸å®šç¾©ï¼šè™•ç†å’ŒåŒ¹é…æ•¸æ“š ---

def process_and_match_data(
    exam_data: Dict[str, Any], 
    subject_map: Dict[frozenset, str], 
    score_distribution_data: Dict[str, Any]
) -> Dict[str, Any]:
    """
    è™•ç†åˆ†ç§‘æ¸¬é©—æ•¸æ“šï¼ŒåŒ¹é…çµ„åˆ¥ä»£è™Ÿä¸¦è¨ˆç®—é”æ¨™æ¯”ä¾‹ã€‚
    """
    matched_count = 0
    percentile_calculated_count = 0
    
    updated_exam_data = exam_data.copy()

    for university, departments in updated_exam_data.items():
        for department, dept_data in departments.items():
            
            # 1. æå–ç§‘ç›®é›†åˆé€²è¡ŒåŒ¹é…
            multipliers = dept_data.get("ç§‘ç›®å€æ•¸", {})
            required_subjects = frozenset(multipliers.keys())
            
            # 2. æŸ¥æ‰¾åŒ¹é…çš„çµ„åˆ¥ä»£è™Ÿ
            group_id = subject_map.get(required_subjects)
            
            dept_data["çµ„åˆ¥ä»£è™Ÿ"] = group_id
            dept_data["é”æ¨™æ¯”ä¾‹"] = None # é è¨­ç‚º None

            if group_id:
                matched_count += 1
                
                # 3. è¨ˆç®—é”æ¨™æ¯”ä¾‹
                
                percentile = get_percentile_from_score(
                    dept_data=dept_data, 
                    group_id=group_id, 
                    score_data=score_distribution_data
                )
                    
                if percentile is not None:
                    # å°‡ç™¾åˆ†æ¯”ä¿ç•™å°æ•¸é»å¾Œå…©ä½
                    dept_data["é”æ¨™æ¯”ä¾‹"] = round(percentile, 2)
                    percentile_calculated_count += 1

    print(f"\n--- åŒ¹é…çµæœæ‘˜è¦ ---")
    print(f"âœ… æˆåŠŸåŒ¹é…åˆ°çµ„åˆ¥çš„æ ¡ç³»æ•¸é‡: {matched_count}")
    print(f"ğŸ“ˆ æˆåŠŸè¨ˆç®—é”æ¨™æ¯”ä¾‹çš„æ ¡ç³»æ•¸é‡: {percentile_calculated_count}")
    print("-" * 20)
    
    return updated_exam_data


def main():
    try:
        # 1. è¼‰å…¥æ•¸æ“š
        with open(DIVISION_EXAM_FILE, 'r', encoding='utf-8') as f:
            division_exam_data = json.load(f)

        with open(SCORE_DISTRIBUTION_FILE, 'r', encoding='utf-8') as f:
            score_distribution_data = json.load(f)

        # 2. å‰µå»ºç§‘ç›®çµ„åˆåˆ°çµ„åˆ¥ä»£è™Ÿçš„æ˜ å°„è¡¨
        subject_group_map = create_subject_group_map(score_distribution_data)

        # 3. è™•ç†ä¸¦åŒ¹é…åˆ†ç§‘æ¸¬é©—æ•¸æ“šï¼Œè¨ˆç®—é”æ¨™æ¯”ä¾‹
        updated_data = process_and_match_data(division_exam_data, subject_group_map, score_distribution_data)

        # 4. å„²å­˜æ›´æ–°å¾Œçš„æ•¸æ“š
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(updated_data, f, ensure_ascii=False, indent=4)
        
        print(f"\nâœ¨ æ•¸æ“šæ•´åˆå®Œæˆï¼çµæœå·²å„²å­˜åˆ° {OUTPUT_FILE}")

    except FileNotFoundError as e:
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆã€‚è«‹ç¢ºä¿å…©å€‹ JSON æª”æ¡ˆ ({DIVISION_EXAM_FILE} å’Œ {SCORE_DISTRIBUTION_FILE}) éƒ½åœ¨ç•¶å‰ç›®éŒ„ä¸­ã€‚éŒ¯èª¤: {e}")
    except json.JSONDecodeError as e:
        print(f"éŒ¯èª¤: JSON æª”æ¡ˆè§£æå¤±æ•—ã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æ˜¯å¦æ­£ç¢ºã€‚éŒ¯èª¤: {e}")
    except Exception as e:
        print(f"ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")


if __name__ == "__main__":
    main()